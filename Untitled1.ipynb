{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3243bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a304ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "with open('spam.csv', 'r', encoding='latin1', errors='replace') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "csv_content = ''.join(lines)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(io.StringIO(csv_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1a6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177d8322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bcd071",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60c7c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lots of null values present in last 3 columns...dropping last 3 columns\n",
    "df.drop(columns=['Unnamed: 2' , 'Unnamed: 3' , 'Unnamed: 4'] , inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d40f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cd8d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'v1':'target' , 'v2':'text'},inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa960a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb4b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e7d7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = encoder.fit_transform(df['target'])\n",
    "# ham = 0 , spam = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8918920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749780fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = encoder.fit_transform(df['target'])\n",
    "# ham = 0 , spam = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad577411",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd089b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306a9999",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicate values\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a150d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicates\n",
    "df = df.drop_duplicates(keep = 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d92b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542bfd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328f47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79940094",
   "metadata": {},
   "outputs": [],
   "source": [
    " df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0645fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec694a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(df['target'].value_counts() , labels = ['ham ' , 'spam'] , autopct=\"%0.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a9f3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data is imbalanced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8fda07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb99d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c31be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be841faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfea7610",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['number_of_characters'] = df['text'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555e2ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d1972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#number of words\n",
    "df['text'].apply(lambda x:nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03980ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['number_of_words'] = df['text'].apply(lambda x:len(nltk.word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cd1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df135394",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['number_of_sentences'] = df['text'].apply(lambda x:len(nltk.sent_tokenize(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f79eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b74c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['number_of_characters' , 'number_of_words' , 'number_of_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b25495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ham messages\n",
    "df[df['target'] == 0][['number_of_characters' , 'number_of_words' , 'number_of_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65241feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spam messages\n",
    "df[df['target'] == 1][['number_of_characters' , 'number_of_words' , 'number_of_sentences']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f8b778",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean of spam characters is almost of ham characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e49bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520f8958",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[df['target'] == 0]['number_of_characters'])\n",
    "sns.histplot(df[df['target'] == 1]['number_of_characters'] , color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551bb835",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[df['target'] == 0]['number_of_words'])\n",
    "sns.histplot(df[df['target'] == 1]['number_of_words'] , color = 'red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ff4505",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df,hue = 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381e3a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "correlation_matrix = numeric_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473cff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cc5509",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(correlation_matrix , annot = True)\n",
    "#number_of_characters has strong correlation/dependency with target compared to number_of_words , number_of_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2828469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing\n",
    "#1. Lower case\n",
    "#2. Tokenisation...breaking into words...eg'hello world' to ['hello', 'world']\n",
    "#3. Removing special characters\n",
    "#4. Removing stop words and punctuation\n",
    "#5. Stemming\n",
    "\n",
    "#All the steps will be performed under 1 function...function name: transform_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3097d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk .corpus import stopwords\n",
    "stopwords.words('english')\n",
    "#stopwords : words which are helpers in sentence but do not contribute to the meaning of sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb9b44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5beb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "ps.stem('loving')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37bb348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_text(text):\n",
    "    text = text.lower()\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    y = []\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            y.append(i)\n",
    "    \n",
    "    text = y[:] #cloning of y cause y is mutable data type\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        if i not in stopwords.words('english') and i not in string.punctuation:\n",
    "            y.append(i)\n",
    "    \n",
    "    text = y[:]\n",
    "    y.clear()\n",
    "    \n",
    "    for i in text:\n",
    "        y.append(ps.stem(i))\n",
    "        \n",
    "    return \" \".join(y) #joins y[i] with string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f69b56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_text('I loved the YT lectures on Machine Learning . How about you?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e50e46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['transformed_text'] = df['text'].apply(transform_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2780bf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281ad5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating word cloud\n",
    "#all important words will be shown with bigger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2416a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7188c72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "wc = WordCloud(width=1000 , height=1000 , min_font_size = 10 , background_color = 'white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1490b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_wc = wc.generate(df[df['target']==1]['transformed_text'].str.cat(sep = \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39ab454",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "plt.imshow(spam_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b884284",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_wc = wc.generate(df[df['target']==0]['transformed_text'].str.cat(sep = \" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0060d97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,18))\n",
    "plt.imshow(ham_wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e519216",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_corpus = []\n",
    "for msg in df[df['target']==1]['transformed_text'].tolist():\n",
    "    for word in msg.split():\n",
    "        spam_corpus.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea9c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(spam_corpus) #arround 10000 words in spam messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133ffae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(spam_corpus).most_common(30)\n",
    "#30 most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cf8451",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "pd.DataFrame(Counter(spam_corpus).most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "54ba7749",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_corpus = []\n",
    "for msg in df[df['target']==0]['transformed_text'].tolist():\n",
    "    for word in msg.split():\n",
    "        ham_corpus.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "15f28dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35404"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ham_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "28afbfdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>u</td>\n",
       "      <td>883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go</td>\n",
       "      <td>404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>get</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gt</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lt</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>come</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>got</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>know</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>like</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>call</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>time</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ok</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>love</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>good</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>want</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ur</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>day</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>need</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>one</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>lor</td>\n",
       "      <td>159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>home</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>think</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>see</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>take</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>still</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>da</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>tell</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>make</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1\n",
       "0       u  883\n",
       "1      go  404\n",
       "2     get  349\n",
       "3      gt  288\n",
       "4      lt  287\n",
       "5       2  284\n",
       "6    come  275\n",
       "7     got  236\n",
       "8    know  236\n",
       "9    like  234\n",
       "10   call  233\n",
       "11   time  219\n",
       "12     ok  217\n",
       "13   love  216\n",
       "14   good  213\n",
       "15   want  208\n",
       "16     ur  197\n",
       "17    day  190\n",
       "18   need  170\n",
       "19    one  165\n",
       "20    lor  159\n",
       "21      4  156\n",
       "22   home  152\n",
       "23  think  149\n",
       "24    see  147\n",
       "25   take  143\n",
       "26  still  143\n",
       "27     da  142\n",
       "28   tell  133\n",
       "29   make  129"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "pd.DataFrame(Counter(ham_corpus).most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eb0591bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using naive bayes algorithms , works well on textual data\n",
    "\n",
    "#converting text to vectors ...using bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "638c4f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "cv = CountVectorizer()\n",
    "tfidf = TfidfVectorizer(max_features=3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aff346c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfidf.fit_transform(df['transformed_text']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3d76099e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5169, 3000)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aa7dcab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6e697c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "889b9806",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "81e9d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ed551ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6883ae06",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "mnb = MultinomialNB()\n",
    "bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "817fff18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9709864603481625\n",
      "[[896   0]\n",
      " [ 30 108]]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "mnb.fit(X_train,y_train)\n",
    "y_pred2 = mnb.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred2))\n",
    "print(confusion_matrix(y_test,y_pred2))\n",
    "print(precision_score(y_test,y_pred2))\n",
    "\n",
    "#precision score = 1..no errors....precision score matters most here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "16e219d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spamclassify():\n",
    "    print(\"Welcome to Spam Classify\")\n",
    "    a = input(\"Enter text which you want to check if it is spam or not: \")\n",
    "    transform_text(a)\n",
    "    b = tfidf.transform([a]) #here we have done vectorisation...vectorisation means\n",
    "    #converting string into individual list\n",
    "    mnb.fit(X_train,y_train)\n",
    "    ypred = mnb.predict(X_test)\n",
    "    result = ypred[0]\n",
    "    if result == 1:\n",
    "        print(\"Spam\")\n",
    "    else:\n",
    "        print(\"Not Spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5a2b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "spamclassify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3844adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bfc4e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
